# Tag 66

Notizen zum Buch [Buch 1](../Buch1.md).

Ab Seite 297:
* Beispiel: Faltung mit Angabe der Dimensionen aller beteiligten Tensoren
  - $(100, 100, 3) \cdot (5, 5, 6) = (96, 96, 6)$

Ab Seite 299:
* Keras
  - `Conv2D(16, (3, 3), activation='relu')`
  - 16 Filter der Größe `(3, 3)`
  - `activation`: Aktivierungsfunktion

* bei Videos:
  - Zeitdimension: dreidimensionale Faltungen

Ab Seite 301:
* Faustregel: Anzahl der Filter im Verlauf des Netzes soll steigen
* `Flatten()`
  - Daten von einem vierstufigen Tensor aus Bildern zu einer Matrix reduzieren

Ab Seite 305:
* Deep Learning

Ab Seite 307:
* rekurrente neuronale Netze
* `GPU`: Graphics Processing Unit
* Wettbewerb: ImageNet
  - Faltungsnetz: AlexNet

Ab Seite 308:
* Hunderte von Schichten
* drei Hauptzweige
  - überwachtes Lernen
  - bestärkendes Lernen (Reinforcement Learning)
  - unüberwachtes Lernen
