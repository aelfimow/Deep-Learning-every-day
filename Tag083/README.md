# Tag 83

Notizen zum Buch [Buch 4](../Buch4.md).

Ab Seite 219:
* Token
  - Start-Token
  - End-Token

* Word-Embedding

* in Large-Language-Modellen
  - mehrere Tausend Dimensionen

Ab Seite 220:
* absolutes Positional Encoding

Ab Seite 221:
* frequenzenbasiertes Positional Encoding
  - Vektorlänge: $d_{emb}$

Ab Seite 223:
* Self-Attention
  - Verständnisraum

Ab Seite 224:
* Vektor für
  - Query
  - Key
  - Value
