# Tag 68

Notizen zum Buch [Buch 1](../Buch1.md).

Ab Seite 346:
* 1-aus-n-Codierung
  - [Tag 30](../Tag030/README.md)
  - [Tag 31](../Tag031/README.md)
  - [Tag 46](../Tag046/README.md)

* abklingende Lernrate
  - [Tag 64](../Tag064/README.md)

* Ableitung, Gradient, partielle Ableitung

* Adam
  - [Tag 64](../Tag064/README.md)

* Aktivierungsfunktion

Ab Seite 347:
* Backpropagation
  - [Tag 53](../Tag053/README.md)

* Batch-Gradientenverfahren
* Batchnormalisierung

* Bias, Biasspalte

Ab Seite 248:
* Broadcasting
  - NumPy
  - Operation auf ein Array anwenden
  - Arrays wie einzelne Werte

* Dichte Schicht
  - vollständig verbundene Schicht

* Dropout
  - einzelne Knoten zufällig abschalten
  - nur beim Training

Ab Seite 350:
* Feature
  - Eingabevariablen

Ab Seite 351:
* Glorot-Initialisierung
  - Xavier-Initialisierung
