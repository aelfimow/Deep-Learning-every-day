# Tag 11

Notizen zum Buch [Buch 1](../Buch1.md).

Ab Seite 48:
* Technik der partiellen Ableitung

Ab Seite 51:
* Zwei partiellen Ableitungen
```math
\frac{\partial L}{\partial w} = \frac{2}{m} \sum_{i=1}^{m} x_{i}((wx_{i} + b) - y_{i})
```
```math
\frac{\partial L}{\partial b} = \frac{2}{m} \sum_{i=1}^{m} ((wx_{i} + b) - y_{i})
```

Ab Seite 53:
* keine Erfolgsgarantie

Ab Seite 54:
* das globale Minimum
  - das lokale Minimum
* eine gute Verlustfunktion muss
  - konvex sein
  - stetig
  - differenzierbar

Ab Seite 55:
* Zusammenfassung
  - Gradientenverfahren
  - Verlustgradienten berechnen
  - einen Schritt in die entgegengesetzte Richtung gehen
  - partielle Ableitungen bilden
  - Grenzen des Verfahrens
  - lokales Minimum
  - globales Minimum
