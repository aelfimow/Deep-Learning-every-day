# Tag 76

Notizen zum Buch [Buch 4](../Buch4.md).

Ab Seite 163:
* Gradientenabstieg
* Feed-forward-Berechnung
* Backpropagation

Ab Seite 164:
* quadratischer Fehler
* Gradientenabstieg
  - Verfahren des steilsten Abstiegs

Ab Seite 165:
* Lernverfahren
  - Backpropagation-Algorithmus
    - kurz: Backprop
  - Verallgemeinerung der Delta-Regel

* Grundidee: Finde die Richtung, in der der Fehler abnimmt

Ab Seite 167:
* Kostenfunktion
  - engl.: cost function
  - engl.: loss function
  - $E(w)$

Ab Seite 168:
* Lernrate
* Nabla
  - $\nabla E(w)$

Ab Seite 173:
* Sigmoide
```math
f(x) = \frac{1}{1 + e^{-x}}
```
